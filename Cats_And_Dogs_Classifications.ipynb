{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras_preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image_Width=128\n",
    "Image_Height=128\n",
    "Image_Size=(Image_Width,Image_Height)\n",
    "Image_Channels=3 #RGB Photos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames=os.listdir(\"./dataset/train\")\n",
    "categories=[]\n",
    "for f_name in filenames:\n",
    "    category=f_name.split('.')[0]\n",
    "    if category=='dog':\n",
    "        categories.append(1)\n",
    "    else:\n",
    "        categories.append(0)\n",
    "\n",
    "df=pd.DataFrame({\n",
    "    'filename':filenames,\n",
    "    'category':categories\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,\\\n",
    "     Dropout,Flatten,Dense,Activation,\\\n",
    "     BatchNormalization\n",
    "\n",
    "model=Sequential()\n",
    "# 3x3 boyutunda 32 adet filtreden oluşan ReLU aktivasyonlu CONV katmanı ekleyelim.\n",
    "model.add(Conv2D(32,(3,3),activation='relu',input_shape=(Image_Width,Image_Height,Image_Channels)))\n",
    "model.add(BatchNormalization()) # Çıktıyı 0 ile 1 arasında normalize ediyor\n",
    "# 2x2 boyutlu çerçeveden oluşan MAXPOOL katmanı ekleyelim. \n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# her seferinde nöronların %25'i atılsın (drop)\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 3x3 boyutunda 64 adet filtreden oluşan ReLU aktivasyonlu CONV katmanı ekleyelim. \n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128,(3,3),activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Tam bağlantılı (fully connected) katmanına geçiş olacağı için düzleştirme yapalım\n",
    "model.add(Flatten())\n",
    "# 128 nörondan oluşan ReLU aktivasyonu FC katmanı ekleyelim \n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "# Her seferinde %50'sini atalım (drop)\n",
    "model.add(Dropout(0.5))\n",
    "# Çıkış katmanına sınıf sayısı kadar (2) Softmax aktivasyonlu nöron ekleyelim\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "\n",
    "# rmsprop optimizasyon yöntemini ve cross entropy yitim (loss) fonksiyonunu kullanalım.\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "  optimizer='rmsprop',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOT 1) BatchNormalization(): Batch normalization sayesinde ağdaki katmanlar, önceki katmanın öğrenmesini beklemek zorunda kalmaz. Eş zamanlı olarak öğrenime olanak sağlar. Eğitimimizin hızlanmasını sağlar.\n",
    "\n",
    "input->hidden layer->BatchNormalization()->hidden layer->BatchNormalization()->hidden layer->BatchNormalization()->output\n",
    "\n",
    "Batch normalization kullanmadan yüksek bir learning rate kullansak, gradyanların yok olması problemiyle karşılaşabiliriz. Ancak batch norm ile bir katmandaki değişiklik diğer katmana yayılmadığı için daha yüksek learning rate’ler kullanabiliriz. Ayrıca batch norm, ağın daha kararlı ve düzenli hale gelmesini sağlar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 126, 126, 32)      896       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 126, 126, 32)     128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 63, 63, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 63, 63, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 61, 61, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 61, 61, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 30, 30, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 30, 30, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 28, 28, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 28, 28, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 14, 14, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               12845568  \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,942,786\n",
      "Trainable params: 12,941,314\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "earlystop = EarlyStopping(patience = 10) # Eğitimin durdurulacağı iyileşme olmayan epoch sayısı\n",
    "# EarlyStopping : Eğitim esnasında takip ettiğiniz değerde belirleyeceğiniz adım — epoch — boyunca iyileşme yoksa eğitim verdiğiniz adım sayısından önce durduruluyor. \n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_accuracy',patience = 2,verbose = 1,factor = 0.5,min_lr = 0.00001)\n",
    "#ReduceLROnPlateau : Eğitim esnasında takip ettiğiniz değerde belirleyeceğiniz adım — epoch — boyunca iyileşme yoksa Öğrenme hızını \n",
    "# sizin belirleyeceğiniz bir katsayıyla çarparak küçültüyor. Bizim kodumuzda 2 adım boyunca test verisi başarımında bir iyileşme olmuyorsa öğrenme hızı 0.5 çarpılarak yarıya indiriliyor.\n",
    "callbacks = [earlystop,learning_rate_reduction]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"category\"] = df[\"category\"].replace({0:'cat',1:'dog'})\n",
    "train_df,validate_df = train_test_split(df,test_size=0.20,\n",
    "  random_state=42)\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)# Hataya karşı indeksi sıfırlıyoruz\n",
    "validate_df = validate_df.reset_index(drop=True)\n",
    "total_train=train_df.shape[0]\n",
    "total_validate=validate_df.shape[0]\n",
    "batch_size=15\n",
    "# batch_size => parametre güncellemesinin gerçekleştiği ağa verilen alt örneklerin sayısıdır. \n",
    "#Toplu boyut için iyi bir varsayılan değer 32 olabilir. Ayrıca 32, 64, 128, 256 ve benzeri değerleri de deneyin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and val data_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 validated image filenames belonging to 2 classes.\n",
      "Found 5000 validated image filenames belonging to 2 classes.\n",
      "Found 20000 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rotation_range=15,\n",
    "                                rescale=1./255,\n",
    "                                shear_range=0.1,\n",
    "                                zoom_range=0.2,\n",
    "                                horizontal_flip=True,\n",
    "                                width_shift_range=0.1,\n",
    "                                height_shift_range=0.1\n",
    "                                )\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(train_df,\n",
    "                                                 \"./dataset/train\",x_col='filename',y_col='category',\n",
    "                                                 target_size=Image_Size,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 batch_size=batch_size)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    validate_df, \n",
    "    \"./dataset/train\", \n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=Image_Size,\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rotation_range=15,\n",
    "                                rescale=1./255,\n",
    "                                shear_range=0.1,\n",
    "                                zoom_range=0.2,\n",
    "                                horizontal_flip=True,\n",
    "                                width_shift_range=0.1,\n",
    "                                height_shift_range=0.1)\n",
    "\n",
    "test_generator = train_datagen.flow_from_dataframe(train_df,\n",
    "                                                 \"./dataset/train\",x_col='filename',y_col='category',\n",
    "                                                 target_size=Image_Size,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1333/1333 [==============================] - 1085s 813ms/step - loss: 0.7475 - accuracy: 0.6378 - val_loss: 0.7872 - val_accuracy: 0.5808 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1333/1333 [==============================] - 1236s 928ms/step - loss: 0.5469 - accuracy: 0.7348 - val_loss: 0.4407 - val_accuracy: 0.7950 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1333/1333 [==============================] - 1301s 942ms/step - loss: 0.5056 - accuracy: 0.7626 - val_loss: 0.5486 - val_accuracy: 0.7411 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1333/1333 [==============================] - ETA: 0s - loss: 0.4727 - accuracy: 0.7804\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "1333/1333 [==============================] - 1138s 853ms/step - loss: 0.4727 - accuracy: 0.7804 - val_loss: 0.4775 - val_accuracy: 0.7796 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1333/1333 [==============================] - 1124s 843ms/step - loss: 0.4140 - accuracy: 0.8129 - val_loss: 0.3192 - val_accuracy: 0.8633 - lr: 5.0000e-04\n",
      "Epoch 6/10\n",
      "1333/1333 [==============================] - 1068s 801ms/step - loss: 0.3938 - accuracy: 0.8205 - val_loss: 0.3421 - val_accuracy: 0.8498 - lr: 5.0000e-04\n",
      "Epoch 7/10\n",
      "1333/1333 [==============================] - ETA: 0s - loss: 0.3779 - accuracy: 0.8314\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "1333/1333 [==============================] - 1062s 797ms/step - loss: 0.3779 - accuracy: 0.8314 - val_loss: 0.3678 - val_accuracy: 0.8322 - lr: 5.0000e-04\n",
      "Epoch 8/10\n",
      "1333/1333 [==============================] - 1069s 802ms/step - loss: 0.3584 - accuracy: 0.8427 - val_loss: 0.2792 - val_accuracy: 0.8831 - lr: 2.5000e-04\n",
      "Epoch 9/10\n",
      "1333/1333 [==============================] - 1057s 793ms/step - loss: 0.3419 - accuracy: 0.8512 - val_loss: 0.2956 - val_accuracy: 0.8737 - lr: 2.5000e-04\n",
      "Epoch 10/10\n",
      "1333/1333 [==============================] - 1017s 763ms/step - loss: 0.3345 - accuracy: 0.8530 - val_loss: 0.2799 - val_accuracy: 0.8851 - lr: 2.5000e-04\n"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "history = model.fit(\n",
    "    train_generator, \n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=total_validate//batch_size, # (//) => mod işleminde kalanı verir.\n",
    "    steps_per_epoch=total_train//batch_size,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "callbacks = [earlystop,learning_rate_reduction]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**saving and loading the .h5 model**\n",
    " \n",
    "**save model**\n",
    "model.save('model1_catsVSdogs_10epoch.h5')\n",
    "print('Model Saved!')\n",
    " \n",
    "**load model**\n",
    "savedModel=load_model('model1_catsVSdogs_10epoch.h5')\n",
    "savedModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved!\n"
     ]
    }
   ],
   "source": [
    "model.save(\"model1_catsVSdogs_10epoch.h5\")\n",
    "print('Model Saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 126, 126, 32)      896       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 126, 126, 32)     128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 63, 63, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 63, 63, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 61, 61, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 61, 61, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 30, 30, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 30, 30, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 28, 28, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 28, 28, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 14, 14, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               12845568  \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,942,786\n",
      "Trainable params: 12,941,314\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "savedModel=load_model('model1_catsVSdogs_10epoch.h5')\n",
    "savedModel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filenames = os.listdir(\"./dataset/test1\")\n",
    "test_df = pd.DataFrame({\n",
    "    'filename': test_filenames\n",
    "})\n",
    "nb_samples = test_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "834/834 [==============================] - 157s 185ms/step\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict(test_generator, steps=np.ceil(nb_samples/batch_size))\n",
    "# np.ceil => Girişin tavanını eleman bazında döndürün. x skalerinin tavanı en küçük tam sayıdır\n",
    "# nb_samples = test_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labels to categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['category'] = np.argmax(predict, axis=-1)\n",
    "\n",
    "label_map = dict((v,k) for k,v in train_generator.class_indices.items())\n",
    "test_df['category'] = test_df['category'].replace(label_map)\n",
    "\n",
    "test_df['category'] = test_df['category'].replace({ 'dog': 1, 'cat': 0 })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prediction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test = test_df.head(10)\n",
    "sample_test.head()\n",
    "plt.figure(figsize=(12, 24))\n",
    "for index, row in sample_test.iterrows():\n",
    "    filename = row['filename']\n",
    "    category = row['category']\n",
    "    img = load_img(\"./dataset/test1/\"+filename, target_size=Image_Size)\n",
    "    plt.subplot(6, 3, index+1)\n",
    "    plt.imshow(img)\n",
    "    plt.xlabel(filename + '(' + \"{}\".format(category) + ')' )\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 254ms/step\n",
      "cat\n"
     ]
    }
   ],
   "source": [
    "results={\n",
    "    0:'cat',\n",
    "    1:'dog'\n",
    "}\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "im=Image.open(\"./dataset/test1/10001.jpg\")\n",
    "im=im.resize(Image_Size)\n",
    "im=np.expand_dims(im,axis=0)\n",
    "im=np.array(im)\n",
    "im=im/255\n",
    "\n",
    "predict_x=model.predict([im])[0]\n",
    "pred = np.argmax(predict_x,axis=-1)\n",
    "print(results[pred])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use program with tkinter!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import *\n",
    "from PIL import ImageTk, Image\n",
    "import numpy\n",
    "from keras.models import load_model\n",
    "model = load_model('cats&dogs_10_epoch.h5')\n",
    "classes = { \n",
    "    0:'its a cat',\n",
    "    1:'its a dog',\n",
    "}\n",
    "#GUI\n",
    "top=tk.Tk()\n",
    "top.geometry('800x600')\n",
    "top.title('CatsVSDogs Classification')\n",
    "top.configure(background='#CDCDCD')\n",
    "label=Label(top,background='#CDCDCD', font=('arial',15,'bold'))\n",
    "sign_image = Label(top)\n",
    "\n",
    "def classify(file_path):\n",
    "    global label_packed\n",
    "    image = Image.open(file_path)\n",
    "    image = image.resize((128,128))\n",
    "    image = numpy.expand_dims(image, axis=0)\n",
    "    image = numpy.array(image)\n",
    "    image = image/255\n",
    "    pred = model.predict([image])[0]\n",
    "    pred = np.argmax(pred,axis=-1)\n",
    "    sign = classes[pred]\n",
    "    print(sign)\n",
    "    label.configure(foreground='#011638', text=sign) \n",
    "\n",
    "def show_classify_button(file_path):\n",
    "    classify_b=Button(top,text=\"Classify image\",\n",
    "   command=lambda: classify(file_path),\n",
    "   padx=10,pady=5)\n",
    "    classify_b.configure(background='#364156', foreground='white',\n",
    "font=('arial',10,'bold'))\n",
    "    classify_b.place(relx=0.79,rely=0.46)\n",
    "\n",
    "def upload_image():\n",
    "    try:\n",
    "        file_path=filedialog.askopenfilename()\n",
    "        uploaded=Image.open(file_path)\n",
    "        uploaded.thumbnail(((top.winfo_width()/2.25),(top.winfo_height()/2.25)))\n",
    "        im=ImageTk.PhotoImage(uploaded)\n",
    "        sign_image.configure(image=im)\n",
    "        sign_image.image=im\n",
    "        label.configure(text='')\n",
    "        show_classify_button(file_path)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "upload=Button(top,text=\"Upload an image\",command=upload_image,padx=10,pady=5)\n",
    "upload.configure(background='#364156', foreground='white',font=('arial',10,'bold'))\n",
    "upload.pack(side=BOTTOM,pady=50)\n",
    "sign_image.pack(side=BOTTOM,expand=True)\n",
    "label.pack(side=BOTTOM,expand=True)\n",
    "heading = Label(top, text=\"Cats&Dogs Classification\",pady=20, font=('arial',20,'bold'))\n",
    "heading.configure(background='#CDCDCD',foreground='#364156')\n",
    "heading.pack()\n",
    "\n",
    "top.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5fe87102cd5f8f942401cb1142057ded62566b3e57c7d6859abcdd55d98882e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
